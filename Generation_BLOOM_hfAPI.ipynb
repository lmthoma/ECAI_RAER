{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "69d0b90fc0a8483995d44f138242dbb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c93b1ec50f843eeb4bfbfc11c56d144",
       "IPY_MODEL_0af0f849ad334cde8fa93003682375e0",
       "IPY_MODEL_2e474dafde3b445f8336d4bda99f0257"
      ],
      "layout": "IPY_MODEL_3e31b05addd54184864e948e1d52410b"
     }
    },
    "6c93b1ec50f843eeb4bfbfc11c56d144": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e9dc855046147bea4e7b1acec527db0",
      "placeholder": "​",
      "style": "IPY_MODEL_8d28dd8258f3490ca093182b6f4f369c",
      "value": ""
     }
    },
    "0af0f849ad334cde8fa93003682375e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3839a1cda254e20b8a31e9de2f8f014",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_622c22ee277b447eab03d9790ad143bc",
      "value": 0
     }
    },
    "2e474dafde3b445f8336d4bda99f0257": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fc755050ef64d688e8cc4fb503d540f",
      "placeholder": "​",
      "style": "IPY_MODEL_2d6e8e4c010348bebb7d2169ffae21fd",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "3e31b05addd54184864e948e1d52410b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e9dc855046147bea4e7b1acec527db0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d28dd8258f3490ca093182b6f4f369c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3839a1cda254e20b8a31e9de2f8f014": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "622c22ee277b447eab03d9790ad143bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3fc755050ef64d688e8cc4fb503d540f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d6e8e4c010348bebb7d2169ffae21fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GFP8rcgavKm",
    "outputId": "5601bff3-8342-4877-9715-8f592eaf89c1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 4.9 MB 23.9 MB/s \n",
      "\u001B[?25hCollecting huggingface-hub<1.0,>=0.9.0\n",
      "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "\u001B[K     |████████████████████████████████| 120 kB 58.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 6.6 MB 50.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import requests"
   ],
   "metadata": {
    "id": "OJ4QshZKa8WX",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "69d0b90fc0a8483995d44f138242dbb7",
      "6c93b1ec50f843eeb4bfbfc11c56d144",
      "0af0f849ad334cde8fa93003682375e0",
      "2e474dafde3b445f8336d4bda99f0257",
      "3e31b05addd54184864e948e1d52410b",
      "2e9dc855046147bea4e7b1acec527db0",
      "8d28dd8258f3490ca093182b6f4f369c",
      "c3839a1cda254e20b8a31e9de2f8f014",
      "622c22ee277b447eab03d9790ad143bc",
      "3fc755050ef64d688e8cc4fb503d540f",
      "2d6e8e4c010348bebb7d2169ffae21fd"
     ]
    },
    "outputId": "22f68b2c-0814-41bd-8416-3c33ca1e4156"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69d0b90fc0a8483995d44f138242dbb7"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = 'bigscience/bloom'\n",
    "\n",
    "experiment_cycles = 100\n",
    "\n",
    "num_prime_tokens = 64\n",
    "num_probe_tokens = 10\n",
    "\n",
    "top_k = 1\n",
    "\n",
    "prime_pause_str = '.' # (Punctuation) token (string) that separates trigrams in prime input\n",
    "\n",
    "cols = ['Setting','TkInp','TkOut1','Inp','Out1']\n",
    "\n",
    "#'w' and 'y' excluded from both, 'q' excluded from consonants\n",
    "vowels = np.array(['a','e','i','o','u','A','E','I','O','U'])\n",
    "consonants = np.array(['b','c','d','f','g','h','j','k','l','m',\n",
    "                       'n','p','r','s','t','v','x','z','B','C','D','F','G','H','J','K','L','M','N','P','R','S','T','V','X','Z'])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer api_org_...\"}\n",
    "API_URL = \"https://api-inference.huggingface.co/models/\"+model_name"
   ],
   "metadata": {
    "id": "4a5q6XcmcLmK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pauses = np.repeat(tokenizer.convert_tokens_to_ids(prime_pause_str), num_prime_tokens)\n",
    "prime_order = np.arange(num_prime_tokens)\n",
    "np.random.shuffle(prime_order)\n",
    "\n",
    "# Restricted Syllables: Preparation\n",
    "v_str = str(vowels).replace(\"['\", \"(\").replace(\"']\", \")\").replace(\"' '\", \"|\")\n",
    "c_str = str(consonants).replace(\"['\", \"(\").replace(\"']\", \")\").replace(\"' '\", \"|\")\n",
    "\n",
    "tkns = []\n",
    "for i in range(len(tokenizer.vocab.keys())): tkns.append(tokenizer.decode([i]))\n",
    "df = pd.DataFrame(data={'Token':tkns})\n",
    "\n",
    "syl_df = pd.DataFrame(data={'Token':[]})\n",
    "syl_df = syl_df.append(df[df.Token.str.match(f'^ {v_str}{c_str}$')]) #_VC\n",
    "syl_df = syl_df.append(df[df.Token.str.match(f'^ {c_str}{v_str}$')]) #_CV\n",
    "syl_df = syl_df.sort_index()\n",
    "syl_df.reset_index(inplace=True)\n",
    "syl_df = syl_df.rename(columns={'index':'TokenID'})\n",
    "syls = syl_df.TokenID.to_numpy()\n",
    "\n",
    "\n",
    "def token_selector(num_tkns, ids_xcl=[]):\n",
    "  ids = random.sample(set(syls)-set(ids_xcl), num_tkns)\n",
    "  return ids\n",
    "\n",
    "def output_generation(prime_ASR, probe_a=None):\n",
    "  temp = [[],[],[],[],[]]\n",
    "\n",
    "  if probe_a == None:\n",
    "    temp[0] = 'no-probe'\n",
    "    prime_input = prime_input_non = tokenizer.decode(prime_ASR.flatten())\n",
    "    max_new=3\n",
    "  else:\n",
    "    temp[0] = 'probe A'\n",
    "    prime_input = tokenizer.decode(np.append(prime_ASR.flatten(), probe_a))\n",
    "    prime_input_non = tokenizer.decode(prime_ASR.flatten())\n",
    "    max_new=2\n",
    "\n",
    "\n",
    "  def query(payload):\n",
    "    data = json.dumps(payload)\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "  data = query({\n",
    "      \"inputs\": prime_input,\n",
    "      \"parameters\": {\"max_new_tokens\": max_new},})\n",
    "\n",
    "  if prime_input_non == prime_input: temp[0] = 'no-probe'\n",
    "  else: temp[0] = 'probe A'\n",
    "  temp[1] = tokenizer.encode(prime_input)\n",
    "  temp[2] = tokenizer.encode(data[0]['generated_text'])[4*num_prime_tokens:]\n",
    "  temp[3] = prime_input\n",
    "  temp[4] = data[0]['generated_text'].replace(prime_input_non,'')\n",
    "\n",
    "  return pd.DataFrame(temp,index=cols).T\n",
    "\n",
    "df_AAB_priming = pd.DataFrame(columns=cols)\n",
    "df_ABA_priming = pd.DataFrame(columns=cols)\n",
    "df_ABB_priming = pd.DataFrame(columns=cols)\n",
    "df_ABCa_priming = pd.DataFrame(columns=cols)\n",
    "df_ABCb_priming = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i_exp in range(experiment_cycles):\n",
    "  prime_AAB = prime_ABA = prime_ABB = np.array([]).astype('int64')\n",
    "\n",
    "  ids_prime_a = token_selector(num_prime_tokens)\n",
    "  ids_prime_b = token_selector(num_prime_tokens,ids_prime_a)\n",
    "\n",
    "  combs_AB = np.transpose((ids_prime_a, ids_prime_b))\n",
    "\n",
    "  prime_AAB = np.insert(combs_AB[:,(0,0,1)],3,pauses,axis=1)\n",
    "  prime_ABA = np.insert(combs_AB[:,(0,1,0)],3,pauses,axis=1)\n",
    "  prime_ABB = np.insert(combs_AB[:,(0,1,1)],3,pauses,axis=1)\n",
    "  prime_ABCa = np.insert(np.insert(combs_AB, 2, np.roll(combs_AB[:,0],len(combs_AB[:,0])//2), axis=1),3,pauses,axis=1)[prime_order] #ABCb\n",
    "  prime_ABCb = np.insert(np.insert(combs_AB, 2, np.roll(combs_AB[:,1],len(combs_AB[:,1])//2), axis=1),3,pauses,axis=1)[prime_order] #ABCb\n",
    "\n",
    "  ids_probe_a = token_selector(num_probe_tokens,np.concatenate((ids_prime_a, ids_prime_b), axis=0))\n",
    "\n",
    "  df_AAB_priming = pd.concat([df_AAB_priming, output_generation(prime_AAB)], ignore_index=True)#AAB priming\n",
    "  df_ABA_priming = pd.concat([df_ABA_priming, output_generation(prime_ABA)], ignore_index=True)#ABA priming\n",
    "  df_ABB_priming = pd.concat([df_ABB_priming, output_generation(prime_ABB)], ignore_index=True)#ABB priming\n",
    "  df_ABCa_priming = pd.concat([df_ABCa_priming, output_generation(prime_ABCa)], ignore_index=True)#ABB priming\n",
    "  df_ABCb_priming = pd.concat([df_ABCb_priming, output_generation(prime_ABCb)], ignore_index=True)#ABB priming\n",
    "\n",
    "  if i_exp%num_probe_tokens == 0:\n",
    "    for a_probe in ids_probe_a:\n",
    "      df_AAB_priming = pd.concat([df_AAB_priming, output_generation(prime_AAB, a_probe)], ignore_index=True)#AAB priming\n",
    "      df_ABA_priming = pd.concat([df_ABA_priming, output_generation(prime_ABA, a_probe)], ignore_index=True)#ABA priming\n",
    "      df_ABB_priming = pd.concat([df_ABB_priming, output_generation(prime_ABB, a_probe)], ignore_index=True)#ABB priming\n",
    "      df_ABCa_priming = pd.concat([df_ABCa_priming, output_generation(prime_ABCa, a_probe)], ignore_index=True)#ABB priming\n",
    "      df_ABCb_priming = pd.concat([df_ABCb_priming, output_generation(prime_ABCb, a_probe)], ignore_index=True)#ABB priming\n",
    "\n",
    "  print(f'{str(datetime.now())}: {i_exp+1} done')\n",
    "\n",
    "folder = model_name.replace('/','.')\n",
    "folder += f'_{experiment_cycles}_{num_prime_tokens}_{num_probe_tokens}_{top_k}/'\n",
    "try: os.mkdir(folder)\n",
    "except FileExistsError: folder = folder\n",
    "\n",
    "time_st = str(datetime.now())\n",
    "\n",
    "df_AAB_priming.to_csv(f'{folder}{time_st}_generate_AAB.csv',sep=';')\n",
    "df_ABA_priming.to_csv(f'{folder}{time_st}_generate_ABA.csv',sep=';')\n",
    "df_ABB_priming.to_csv(f'{folder}{time_st}_generate_ABB.csv',sep=';')\n",
    "df_ABCa_priming.to_csv(f'{folder}{time_st}_generate_ABCa.csv',sep=';')\n",
    "df_ABCb_priming.to_csv(f'{folder}{time_st}_generate_ABCb.csv',sep=';')"
   ],
   "metadata": {
    "id": "WtAxvehvgc7u",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fd54b5a3-b0d2-4c38-d34b-014777471c10"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-09-27 16:11:18.221489: 1 done\n",
      "2022-09-27 16:11:29.130030: 2 done\n",
      "2022-09-27 16:11:48.994870: 3 done\n",
      "2022-09-27 16:12:08.715181: 4 done\n",
      "2022-09-27 16:12:19.505217: 5 done\n",
      "2022-09-27 16:12:43.905787: 6 done\n",
      "2022-09-27 16:12:59.718952: 7 done\n",
      "2022-09-27 16:13:20.301803: 8 done\n",
      "2022-09-27 16:13:40.966181: 9 done\n",
      "2022-09-27 16:14:04.989424: 10 done\n",
      "2022-09-27 16:14:32.005991: 11 done\n",
      "2022-09-27 16:14:33.798539: 12 done\n",
      "2022-09-27 16:14:35.625457: 13 done\n",
      "2022-09-27 16:14:41.709591: 14 done\n",
      "2022-09-27 16:14:43.553504: 15 done\n",
      "2022-09-27 16:14:45.343635: 16 done\n",
      "2022-09-27 16:14:47.152507: 17 done\n",
      "2022-09-27 16:14:48.915168: 18 done\n",
      "2022-09-27 16:14:50.710782: 19 done\n",
      "2022-09-27 16:14:53.752724: 20 done\n",
      "2022-09-27 16:15:12.602002: 21 done\n",
      "2022-09-27 16:15:14.470416: 22 done\n",
      "2022-09-27 16:15:16.275914: 23 done\n",
      "2022-09-27 16:15:20.482976: 24 done\n",
      "2022-09-27 16:15:22.384899: 25 done\n",
      "2022-09-27 16:15:25.517636: 26 done\n",
      "2022-09-27 16:15:34.593922: 27 done\n",
      "2022-09-27 16:15:36.386400: 28 done\n",
      "2022-09-27 16:15:38.239042: 29 done\n",
      "2022-09-27 16:15:40.082772: 30 done\n",
      "2022-09-27 16:16:04.487194: 31 done\n",
      "2022-09-27 16:16:06.304866: 32 done\n",
      "2022-09-27 16:16:08.124508: 33 done\n",
      "2022-09-27 16:16:09.983022: 34 done\n",
      "2022-09-27 16:16:15.965173: 35 done\n",
      "2022-09-27 16:16:17.895245: 36 done\n",
      "2022-09-27 16:16:20.937333: 37 done\n",
      "2022-09-27 16:16:22.881200: 38 done\n",
      "2022-09-27 16:16:24.700820: 39 done\n",
      "2022-09-27 16:16:27.768412: 40 done\n",
      "2022-09-27 16:16:49.641074: 41 done\n",
      "2022-09-27 16:16:51.429443: 42 done\n",
      "2022-09-27 16:16:53.244531: 43 done\n",
      "2022-09-27 16:16:55.052039: 44 done\n",
      "2022-09-27 16:16:56.915409: 45 done\n",
      "2022-09-27 16:16:58.805524: 46 done\n",
      "2022-09-27 16:17:00.654316: 47 done\n",
      "2022-09-27 16:17:03.782710: 48 done\n",
      "2022-09-27 16:17:05.607439: 49 done\n",
      "2022-09-27 16:17:08.675733: 50 done\n",
      "2022-09-27 16:17:33.631432: 51 done\n",
      "2022-09-27 16:17:35.549154: 52 done\n",
      "2022-09-27 16:17:37.382411: 53 done\n",
      "2022-09-27 16:17:39.243410: 54 done\n",
      "2022-09-27 16:17:41.120254: 55 done\n",
      "2022-09-27 16:17:42.910935: 56 done\n",
      "2022-09-27 16:17:45.998769: 57 done\n",
      "2022-09-27 16:17:47.813919: 58 done\n",
      "2022-09-27 16:17:49.699397: 59 done\n",
      "2022-09-27 16:17:51.657020: 60 done\n",
      "2022-09-27 16:18:10.718351: 61 done\n",
      "2022-09-27 16:18:13.783340: 62 done\n",
      "2022-09-27 16:18:15.630685: 63 done\n",
      "2022-09-27 16:18:17.480446: 64 done\n",
      "2022-09-27 16:18:19.301915: 65 done\n",
      "2022-09-27 16:18:22.460951: 66 done\n",
      "2022-09-27 16:18:25.408205: 67 done\n",
      "2022-09-27 16:18:27.269078: 68 done\n",
      "2022-09-27 16:18:31.630486: 69 done\n",
      "2022-09-27 16:18:33.436090: 70 done\n",
      "2022-09-27 16:19:00.804105: 71 done\n",
      "2022-09-27 16:19:02.653614: 72 done\n",
      "2022-09-27 16:19:04.523067: 73 done\n",
      "2022-09-27 16:19:06.431355: 74 done\n",
      "2022-09-27 16:19:08.238333: 75 done\n",
      "2022-09-27 16:19:10.136359: 76 done\n",
      "2022-09-27 16:19:13.357672: 77 done\n",
      "2022-09-27 16:19:15.218010: 78 done\n",
      "2022-09-27 16:19:18.279889: 79 done\n",
      "2022-09-27 16:19:20.050695: 80 done\n",
      "2022-09-27 16:19:38.779759: 81 done\n",
      "2022-09-27 16:19:40.662632: 82 done\n",
      "2022-09-27 16:19:42.538877: 83 done\n",
      "2022-09-27 16:19:44.361135: 84 done\n",
      "2022-09-27 16:19:46.205733: 85 done\n",
      "2022-09-27 16:19:48.049415: 86 done\n",
      "2022-09-27 16:19:49.873854: 87 done\n",
      "2022-09-27 16:19:51.754130: 88 done\n",
      "2022-09-27 16:19:54.923002: 89 done\n",
      "2022-09-27 16:19:56.831883: 90 done\n",
      "2022-09-27 16:20:17.778969: 91 done\n",
      "2022-09-27 16:20:19.590457: 92 done\n",
      "2022-09-27 16:20:22.657362: 93 done\n",
      "2022-09-27 16:20:24.454286: 94 done\n",
      "2022-09-27 16:20:26.258847: 95 done\n",
      "2022-09-27 16:20:29.369600: 96 done\n",
      "2022-09-27 16:20:31.214625: 97 done\n",
      "2022-09-27 16:20:34.289305: 98 done\n",
      "2022-09-27 16:20:36.055955: 99 done\n",
      "2022-09-27 16:20:37.929452: 100 done\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download"
   ],
   "metadata": {
    "id": "QUTbyAwhiPKH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r downAPI.zip /content/bigscience.bloom_100_64_10_1\n",
    "from google.colab import files\n",
    "files.download('downAPI.zip')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "ZvG9L8jogs7g",
    "outputId": "b8f63452-ddaa-4006-a9df-bd44879bff02"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "updating: content/bigscience.bloom_100_64_10_1/ (stored 0%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:18:55.917920_generate_AAB.csv (deflated 83%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:18:55.917920_generate_ABA.csv (deflated 79%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:18:55.917920_generate_ABB.csv (deflated 82%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:18:55.917920_generate_ABCa.csv (deflated 78%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:18:55.917920_generate_ABCb.csv (deflated 78%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:52:20.057043_generate_ABB.csv (deflated 82%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:52:20.057043_generate_AAB.csv (deflated 82%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:52:20.057043_generate_ABCb.csv (deflated 78%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:52:20.057043_generate_ABA.csv (deflated 78%)\n",
      "updating: content/bigscience.bloom_100_64_10_1/2022-09-27 15:52:20.057043_generate_ABCa.csv (deflated 78%)\n",
      "  adding: content/bigscience.bloom_100_64_10_1/2022-09-27 16:20:37.930293_generate_ABA.csv (deflated 79%)\n",
      "  adding: content/bigscience.bloom_100_64_10_1/2022-09-27 16:20:37.930293_generate_AAB.csv (deflated 83%)\n",
      "  adding: content/bigscience.bloom_100_64_10_1/2022-09-27 16:20:37.930293_generate_ABCa.csv (deflated 78%)\n",
      "  adding: content/bigscience.bloom_100_64_10_1/2022-09-27 16:20:37.930293_generate_ABCb.csv (deflated 78%)\n",
      "  adding: content/bigscience.bloom_100_64_10_1/2022-09-27 16:20:37.930293_generate_ABB.csv (deflated 82%)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "download(\"download_6ed99654-230d-4df2-8fe0-d7d164323dc3\", \"downAPI.zip\", 1342585)"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!rm -r /content/down*\n",
    "!rm -r /content/big*"
   ],
   "metadata": {
    "id": "xIb0ZX8WpPBh"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
